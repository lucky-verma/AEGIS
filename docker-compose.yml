services:
  scraper:
    build: ./scraper_service
    ports:
      - "8081:8081"
    environment:
      - CRAWL4AI_BROWSER=chromium
    networks:
      - agentic-net

  # app:
  #   build: .
  #   ports:
  #     - "8501:8501"
  #   environment:
  #     - SCRAPER_SERVICE=http://host.docker.internal:8081
  #     - SEARXNG_HOST=http://host.docker.internal:8080
  #     - OLLAMA_HOST=http://host.docker.internal:11434
  #     - PYTHONUNBUFFERED=1
  #   volumes:
  #     - ./src:/app/src
  #     - ./.streamlit:/app/.streamlit  # Mount 
  #   depends_on:
  #     - scraper
  #     - ollama
  #   networks:
  #     - agentic-net
  #   logging:
  #     driver: json-file
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
    environment:
      - OLLAMA_GPU_LAYERS=100
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - agentic-net

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_API_BASE_URL=http://host.docker.internal:11434/api
    volumes:
      - ./ollama-webui:/app/backend/data
    networks:
      - agentic-net

networks:
  agentic-net:
